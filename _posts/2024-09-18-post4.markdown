---
layout: post
title: "The Fundamentals of Hypothesis Testing Concepts "
date: 2024-09-18
categories: main 
image: /assets/images/post4/img1.jpg 
excerpt: "??"      

---

### Two Sample z-test for Means

Now that we have familiarized ourselves with the most important concepts in Hypothesis Testing, we are ready to make our understanding more concrete by looking at a specific Hypothesis Test—namely, the two sample z-test for means. 

As the name implies, this test assumes a normal distribution (z distribution) and is used to compare means between two independent groups. This is particularly fitting for our item recommendation module example, where we compare mean GMV/visitor between the Test and Control groups. The underlying population in this example is assumed to be normally distributed, but even if it weren’t, the Central Limit Theorem (CLT) applies due to the large sample sizes, making the sampling distribution of the means approximately normal.

In general, the two sample z-test for means is probably the most widely used Hypothesis Test in an online A/B testing context.

#### How does the two-sample z-test for means work?

This test works by measuring how far the observed difference between sample means is from the expected difference under the Null Hypothesis (typically zero), in terms of standard deviations—or more accurately, standard errors. This measurement is called the z-statistic, and the area under the standard normal distribution curve beyond the absolute value of the z-statistic gives us the p-value, which indicates how extreme the observation is.

In essence, the z-test involves just calculating the z-statistic and the corresponding p-value.

#### Equations for Calculating the z-statistic

**Distance:**
The z-statistic measures the distance between the observed difference in sample means and the expected difference under the Null Hypothesis, which is typically zero. This can be expressed as:

$$
(\bar{X}_{\text{test}} - \bar{X}_{\text{control}})
$$

**Standard Error:**
The z-statistic expresses this distance in terms of the standard deviation of the distribution under the Null Hypothesis. The standard deviation of the means is called the standard error, and in the case of the Null Hypothesis, which involves the difference between two means, it is calculated as follows:

By definition:

$$
\text{Standard Error} = \sqrt{\text{Var}(\bar{X}_{\text{test}} - \bar{X}_{\text{control}})}
$$

Because the two samples are independent, the variance of the difference is the sum of the variances of each sample mean:

$$
\text{Standard Error} = \sqrt{\text{Var}(\bar{X}_{\text{test}}) + \text{Var}(\bar{X}_{\text{control}})}
$$

Substituting the variances of the sample means, we get:

$$
\text{Standard Error} = \sqrt{\frac{s^2_{\text{test}}}{n_{\text{test}}} + \frac{s^2_{\text{control}}}{n_{\text{control}}}}
$$

**Note:** The \\(s\\) in the above equation represents the sample standard deviation, which approximates the population standard deviation \\(\sigma\\). The accuracy of this approximation improves with larger sample sizes.

$$
s = \sqrt{\frac{1}{n-1} \sum_{i=1}^{n} (X_i - \bar{X})^2}
$$

Where:
- \\(n\\) is the sample size,
- \\(X_i\\) represents each individual observation,
- \\(\bar{X}\\) is the sample mean.

As mentioned, the Null Hypothesis assumes that there is no difference between the Test and Control distributions. This means we can assume that the standard deviations of both groups are the same. This allows us to simplify the standard error formula by using the pooled standard deviation, \\(s_p\\):

$$
s_p = \sqrt{\frac{(n_{\text{test}} - 1)s_{\text{test}}^2 + (n_{\text{control}} - 1)s_{\text{control}}^2}{n_{\text{test}} + n_{\text{control}} - 2}}
$$

The standard error then simplifies to:

$$
\text{Standard Error} = s_p \sqrt{\frac{1}{n_{\text{test}}} + \frac{1}{n_{\text{control}}}}
$$

Using the above, we then get the z-statistic formula:

$$
Z = \frac{\bar{X}_{\text{test}} - \bar{X}_{\text{control}}}{s_p \sqrt{\frac{1}{n_{\text{test}}} + \frac{1}{n_{\text{control}}}}}
$$

#### Finding the p-value:

Once we have the z-statistic, we can find the corresponding p-value by looking it up in a Z-table or using software, considering the appropriate area under the curve depending on whether the test is left-tailed, right-tailed, or two-tailed.

The above explanation fully captures what a z-test for means entails. However, there is one other important calculation related to the z-test that is typically performed before running the test: the calculation of Statistical Power.

As mentioned earlier:

$$
\text{Statistical Power} = 1 - \beta
$$

Beta \\( \beta \\) represents the probability that the test will fail to reject the Null Hypothesis when the Alternative Hypothesis is true. This occurs when the test statistic under the Alternative Hypothesis falls within the non-significant region of the distribution under the Null Hypothesis, below the critical value \\(\ z_{\alpha} \ \\).

To calculate beta, \\( z_{\alpha} \\) needs to be expressed with respect to the distribution under the Alternative Hypothesis. This transformation is necessary because the critical value \\( z_{\alpha} \\) was originally defined under the Null Hypothesis. To accurately assess the overlap between the Null and Alternative Hypothesis distributions, we must adjust \\( z_{\alpha} \\) to account for the shift in the mean when moving from the Null to the Alternative Hypothesis.

This is done by first expressing the MDE (Minimum Detectable Effect) as a z-statistic ( \\( z_{\text{MDE}} \\) ) and then subtracting \\( z_{\text{MDE}} \\) from \\( z_{\alpha} \\).

$$
z_{\text{MDE}} = \frac{\text{MDE}}{\text{Standard Error}} = \frac{\text{MDE}}{\sqrt{\frac{s^2_{\text{test}}}{n_{\text{test}}} + \frac{s^2_{\text{control}}}{n_{\text{control}}}}}
$$

Beta is therefore calculated as:

$$
\beta = P\left(z > z_{\alpha} - z_{\text{MDE}}\right)
$$

And Statistical Power is:

$$
\text{Statistical Power} = 1 - \beta = 1 - P\left(z > z_{\alpha} - \frac{\text{MDE}}{\sqrt{\frac{s^2_{\text{test}}}{n_{\text{test}}} + \frac{s^2_{\text{control}}}{n_{\text{control}}}}}\right)
$$

Given that Statistical Power is conventionally fixed at 80% and alpha is set to 0.05, we can examine the relationship between MDE and the number of samples for a given sample standard deviation \\( s \\) in the accompanying chart.

### Two Sample z-test for Proportions

This is essentially the same as the two-sample z-test for means, in the sense that it deals with independent groups, requires the sampling distribution to be normal, and determines how extreme the observed data is with respect to the distribution under the Null Hypothesis, by calculating the z-statistic and p-value.

The only difference is that this test deals with proportions in categorical data—specifically binary outcomes (e.g., success/failure)—while the other uses continuous data for calculating means. Whereas the z-test for means is used for testing differences in GMV/visitors, the proportions test is used for testing differences in conversion rates.


#### A Quick Note on Proportions, Ratios, and Means:

As an aside, proportions, ratios, and means are often conflated with each other. These are related but different concepts. Proportions represent part of a whole—they are a fraction or percent. Ratios are a comparison or relationship between data—the data can be unrelated and do not have to form part of a whole. Notably, a proportion can be expressed as a ratio, but a ratio is not a proportion. Means are a summary of the distribution of data, i.e., a summary of a series of values to understand what is the “typical” value. This is in contrast to proportions or ratios that involve the division of one quantity by another. We could take the ratio of means (e.g., mean height of women/mean height of men) or the mean of ratios (e.g., mean of height/weight for women); however, these serve different analytical purposes. The ratio of means shows a relationship between two groups, while the mean of ratios provides a summary within a group—each offering distinct insights depending on the context.


#### Application of the Central Limit Theorem (CLT) to Proportions:

It was mentioned in the case of the z-test for means that the CLT guarantees that the sampling distribution of means approximates a normal distribution, which in turn allows us to use the z-test. On the other hand, it was mentioned earlier that the CLT does not necessarily apply to all statistics—medians and percentiles being examples.

To clarify, the CLT does indeed apply to proportions. This is because proportions can be modeled as the mean of a series of binary outcomes from a binomial distribution. Under the CLT, the sampling distribution of these means (proportions) from a binomial distribution approximates a normal distribution as the sample size increases, enabling us to apply the z-test.

But going back to the two-sample z-test for proportions, the formula for calculating the standard error, and therefore the z-statistic, looks slightly different from what was used in the case of means, as shown below.


#### Standard Error for the Difference in Proportions:

By definition:

$$

\text{Standard Error} = \sqrt{\text{Var}(\bar{X}_{\text{test}} - \bar{X}_{\text{control}})}

$$

Because the two samples are independent, the variance of the difference is the sum of the variances of each sample mean:

$$

\text{Standard Error} = \sqrt{\text{Var}(\bar{X}_{\text{test}}) + \text{Var}(\bar{X}_{\text{control}})}

$$

Substituting the variances of the sample proportions, we use \\( p_{\text{test}} \\) and \\( p_{\text{control}} \\) to represent the sample proportions for the test and control groups, respectively:

$$

\text{Standard Error} = \sqrt{\frac{p_{\text{test}}(1 - p_{\text{test}})}{n_{\text{test}}} + \frac{p_{\text{control}}(1 - p_{\text{control}})}{n_{\text{control}}}}

$$

Where:
- \\( p_{\text{test}} = \frac{x_{\text{test}}}{n_{\text{test}}} \\) is the proportion of successes in the test group, where \\( x_{\text{test}} \\) is the number of successes in the test group, and \\( n_{\text{test}} \\) is the size of the test group.
- \\( p_{\text{control}} = \frac{x_{\text{control}}}{n_{\text{control}}} \\) is the proportion of successes in the control group, where \\( x_{\text{control}} \\) is the number of successes in the control group, and \\( n_{\text{control}} \\) is the size of the control group.

#### Pooled Estimate:

Under the Null Hypothesis, we assume that the true proportions in both groups are equal, so we use a pooled estimate \\( \hat{p} \\), calculated as:

$$

\hat{p} = \frac{x_{\text{test}} + x_{\text{control}}}{n_{\text{test}} + n_{\text{control}}}

$$

Using \\( \hat{p} \\), the standard error formula becomes:

$$

\text{Standard Error} = \sqrt{\frac{\hat{p}(1 - \hat{p})}{n_{\text{test}}} + \frac{\hat{p}(1 - \hat{p})}{n_{\text{control}}}}

$$

We can then factor out \\( \hat{p}(1 - \hat{p}) \\):

$$

\text{Standard Error} = \sqrt{\hat{p}(1 - \hat{p}) \left( \frac{1}{n_{\text{test}}} + \frac{1}{n_{\text{control}}} \right)}

$$

#### Z-statistic for the Difference in Proportions:

As before, the z-statistic is calculated by dividing the observed difference by the standard error, to measure how many standard errors the observed difference is from the expected difference under the Null Hypothesis:

$$

Z = \frac{p_{\text{test}} - p_{\text{control}}}{\sqrt{\hat{p}(1 - \hat{p}) \left( \frac{1}{n_{\text{test}}} + \frac{1}{n_{\text{control}}} \right)}}

$$

#### Statistical Power:

The formula for Statistical Power in the case of the difference in proportions is fundamentally similar to that in the case of the difference in means:

$$

\text{Statistical Power} = 1 - \beta = 1 - P\left(z > z_{\alpha} - z_{\text{MDE}}\right)

$$

However, due to the difference in how the standard error is calculated for proportions, the formula becomes:

$$

\text{Statistical Power} = 1 - P\left(z > z_{\alpha} - \frac{\text{MDE}}{\sqrt{\hat{p}(1 - \hat{p}) \left( \frac{1}{n_{\text{test}}} + \frac{1}{n_{\text{control}}} \right)}}\right)

$$

Where:
- \\( \hat{p} \\) represents the pooled proportion, calculated as:

$$

\hat{p} = \frac{\text{number of successes in both groups}}{\text{total sample size of both groups}}

$$

- \\( \text{MDE} \\) is the Minimum Detectable Effect, expressed as the difference in proportions you want to detect.

### Other Hypothesis Tests

So far, we have covered two variants of the Z-test: the two-sample Z-test for means and the two-sample Z-test for proportions. However, there are other variations of the Z-test, such as the one-sample Z-test (where instead of a Test and Control group, a single group is compared to some specified threshold) and the paired Z-test (where instead of independent Test and Control groups, the group being measured is related in some way). Beyond the Z-test, there are also various other types of hypothesis tests—some that don't rely on assumptions about the sampling distribution, and others that allow us to assess changes across multiple variables.

Next, we will explore a hypothesis test that measures differences in medians. This test is valuable because medians, being more robust to outliers than means, are an important statistic. Additionally, the test provides a contrast to the z-test.

### Mann-Whitney U Test

This test tells us if there is a statistically significant difference between the distributions of two samples (i.e. between the Test and Control groups). And from that, we in turn infer if the difference in medians of the two samples are statistically significant.

Unlike the z-test, this test does not require the sampling distribution to be normal, or make any other assumptions on the sampling or population distributions. In fact this particular test does not even work directly with the data. Instead, it works by comparing the relative rank of the data across the groups.

Under the Null Hypothesis, the expectation is that there is no difference between the two groups—implying that the ranks are randomly distributed between the groups. Deviations from this expectation are also assessed based on the ranked data; although for large samples, these deviations can be further transformed into z-scores for comparison to a normal distribution. The specifics of all this will be illustrated below using an example.
The Mann-Whitney test is applicable to continuous or ordinal data. Due to its applicability to continuous data, we can in fact once again leverage our item recommendation module example.

Let us imagine we have 6 visitors in the Control group who are exposed to the old module and 6 visitors in the Test group who are exposed to the new module. The GMV/visitor for each visitor in each group is illustrated below. 

As mentioned, the test involves pooling the observations from the two samples into one combined sample, keeping track of which sample each observation comes from, and then ranking lowest to highest from 1 to n_control+n_test, respectively.

Next we compare the sum of each sample’s across-group rank to its within group rank.

A data point's across-group rank is higher than its within-group rank when a lower-valued data point exists in the other group (which pushes the given data point to a higher rank). The difference between the sum of across-group and within-group ranks reflects the number of times the other group's values are smaller than those in the given group. This difference effectively measures how much one group's values tend to be larger than the other's.

So for instance, the GMV/Visitor datapoint of 11.3 in the Control group has an across-group rank of 4 but a within-group rank of 3 because when the samples are combined, there is one Test group datapoint i.e. 11.0 that is lower than that Control group datapoint. 

Similarly the datapoint of 11.5 in the Control group has an across-group rank of 6 but a within-group rank of 4, because there are two Test group datapoints – 11.0 and 11.4 that are smaller than the Control group datapoint.
In this way there are 11 instances when the Test group datapoint is smaller than the Control group datapoint, as reflected in the U Statistic of 11 for the Control group.

In this way, there are 11 instances where the Test group’s data point is smaller than the Control group’s, reflected in the U Statistic of 11 for the Control group.

The U Statistic for the Test group is 25, implying that there are 25 instances where there is a Control group datapoint smaller than a Test group datapoint.

To summarize, the formula for the U Statistic is (using the Control group for example):

$$
U_{\text{control}} = R_{\text{control}} - \left(n_{\text{control}} \times \left(n_{\text{control}} + 1\right)\right)/2,
$$

where \\(R_{\text{control}}\\) is the sum of the across-group rank of the Control data and  \\(\left(n_{\text{control}} \times \left(n_{\text{control}} + 1\right)\right)/2\\) is the sum of the within-group rank of the Control data, derived using arithmetic mean.

The U statistic can be thought of as a rank-based measure of separation between two distributions. Under the null hypothesis, we assume there is no difference between the Test and Control distributions, which implies that, on average, half of the values in one group will rank higher than those in the other group.

To determine statistical significance, we use the smaller of the two U statistic values and compare it to the expected distribution under the null hypothesis. For small samples, this involves comparing the U statistic to a critical value from the Mann-Whitney distribution table, which gives an exact p-value.

It’s important to note that the choice of the smaller U value is purely a matter of convention. The two U statistics are symmetric (i.e., \\(U_{\text{control}} + U_{\text{test}} = n_{\text{control}} \times n_{\text{test}}\\)), meaning they carry the same information. However, Mann-Whitney tables are designed for comparison using the smaller U statistic.

For larger samples, it becomes computationally impractical to create a distribution table for exact p-values. In such cases, we leverage the Central Limit Theorem (CLT). While the CLT is often associated with the convergence of sample means to a normal distribution for large samples, it more generally states that for independent and identically distributed (i.i.d.) large samples, the scaled sum of the data (which includes the mean but not the median or percentiles) converges to a normal distribution.

The U statistic, being based on the sum of across-group ranks and within-group ranks, fits this framework. Thus, for large samples, the CLT guarantees that the U statistic approximates a normal distribution.

Any U statistic can therefore be converted to a z-score and compared to the normal distribution under the null hypothesis to assess how extreme the observed value is. As mentioned earlier, under the null hypothesis, we expect half the values in one group to be higher than that in the other group. It was also mentioned that \\(U_{\text{control}} + U_{\text{test}}\\) is always \\(n_1 \times n_2\\). Given this, the mean value under the Null Hypothesis is \\((n_1 \times n_2)/2\\)

Additionally, the standard deviation of the U statistic under the null hypothesis is given by:

$$
\sigma_U = \sqrt{\frac{n_1 \times n_2 \times (n_1 + n_2 + 1)}{12}}
$$

(Note that the formula for standard deviation changes when there are ties in the rankings to 

$$
\sigma_U = \sqrt{ \frac{n_1 \times n_2 \times (n_1 + n_2 + 1)}{12} - \frac{\sum_{i} (t_i^3 - t_i)}{12(n_1 + n_2)(n_1 + n_2 - 1)} }
$$

Where \\( t_i \\) is the number of tied ranks in the \\( i \\)-th group of ties. However, further details on this are beyond the scope of this discussion.)

The z-score of the U statistic is then calculated as:

$$
Z = \frac{U - \mu_U}{\sigma_U}
$$

This z-score can be compared to the standard normal distribution to determine statistical significance.

Note that, it was mentioned earlier that using the smaller U was a matter of convention, necessary when finding exact p-values from the Mann-Whitney distribution table. In contrast, for large samples, either of the U Statistic yields the same p-value.

In our example, we get \\(\mu_U = 18\\), and  \\(\sigma_U = 6.244\\). Since \\(U_{\text{control}} = 11\\) and \\(U_{\text{test}} = 25\\), we get

$$
Z_{\text{control}} = \frac{11 - 18}{6.244} \approx \frac{-7}{6.244} \approx -1.12
$$

and

$$
Z_{\text{test}} = \frac{25 - 18}{6.244} \approx \frac{7}{6.244} \approx 1.12
$$

As can be seen above, the two U Statistics yield symmetric  z-scores and therefore the same p-value i.e. 0.2623 (which is not statistically significant). 

Note, the sample sizes in our example (\\(\text{control} = n_{\text{test}} = 6\\)) are too small to use the Z-score approach accurately. The rule of thumb is that we require at least 30 samples for the z-score based approach to apply. However, the above is intended to illustrate the symmetry in z-scores which still holds for larger sample sizes, where the normal approximation becomes valid.

### A Disclaimer on Inferring Medians

The Mann-Whitney U test can detect differences between distributions, but it does not automatically imply that the medians are different unless the two distributions have the same shape. Differences in the overall shape of the distributions (e.g., spread or skewness) can also lead to a rejection of the null hypothesis, even when the medians are the same.

This is an important caveat when using non-parametric tests like Mann-Whitney, as they test for differences in ranks and distributions rather than focusing solely on central tendencies like the median.

For example, in the image below, the medians of both distributions are identical. However, the null hypothesis would still be rejected in this case because the distributions are skewed in different directions. 

In short, the Mann-Whitney test can tell us if the distributions of two groups are different. However, it does not necessarily indicate that the medians of the distributions are different unless the distributions have the same shape. Inferring that the medians are different would require the additional assumption that the distributions are similarly shaped.

This is why Mann-Whitney tests are often reported as stating: “The medians of the two groups were different, and there was a statistically significant difference detected between the two groups,” as opposed to “The medians of the two groups were statistically significantly different.”

### Statistical Power

The statistical power calculation for the Mann-Whitney test is not as straightforward as that for z-tests. For small samples, a formula-based power calculation is generally not possible due to the non-normality of the U statistic’s distribution. In these cases, we rely on Monte Carlo simulations or exact methods to estimate power (Monte Carlo is to be discussed in a later section).

For large samples, we can use the asymptotic normal approximation of the U statistic, similar to the z-test, to calculate power. However, regardless of sample size, the MDE (Minimum Detectable Effect) for the Mann-Whitney test must be handled with care.

In z-tests, the MDE is typically defined as a difference in means. In the Mann-Whitney test, since the test compares the ranks of two groups rather than their raw data, it makes sense to approach the MDE as a shift in ranks, which is reflected in the U statistic. However, because the U statistic may not be easily interpretable, we often express the effect size in terms of the probability of superiority, which is a transformation of the U statistic.

The probability of superiority is calculated as:

$$
\text{Probability of Superiority} = \frac{U}{n_1 \times n_2}
$$

This tells us the likelihood that a randomly selected value from the test group will exceed a randomly selected value from the control group, making it an intuitive measure of effect size in the Mann-Whitney test.

An example of power calculation for large sample Mann-Whitney test is as follows (however we will still use our previous example of n_control = n_test = 6, which does not technically apply but enables simpler illustration):

As seen before, in our example \\(n_{\text{control}} = n_{\text{test}} = 6\\), \\(\mu_U = 18\\) and \\(\sigma_U = 6.244\\)

Let us say we want our probability of superiority to be 0.65. Therefore our \\(U_{\text{MDE}} = n_{\text{control}} \times n_{\text{test}} \times \text{Probability of Superiority} = 6 \times 6 \times 0.65 = 23.4\\)

$$
Z_{\text{Mde}} = \frac{U_{\text{mde}} - \mu_U}{\sigma_u} = 0.865
$$

In the section for z-test, we have seen that the formula for statistical power = 1 - P(Z > Z_{\alpha} - Z_{\text{mde}}) = P(Z > Z_{\text{mde}} - Z_{\alpha})

For a two-tailed test, the critical value of \\(Z_{\alpha}\\) for a 5% significance level is 1.96.

$$
Z_{\text{Power}} = Z_{\text{MDE}} - Z_{\alpha} = 0.865 - 1.96 = -1.095
$$

From Z-tables, the probability of obtaining a Z-score greater than -1.095 is approximately 0.862.

Therefore, the power of the test is approximately 86.2%.
