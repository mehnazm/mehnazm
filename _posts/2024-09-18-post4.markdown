---
layout: post
title: "The Fundamentals of Hypothesis Testing Concepts "
date: 2024-09-18
categories: main 
image: /assets/images/post4/img1.jpg 
excerpt: "??"      

---

### Two Sample z-test for Means

Now that we have familiarized ourselves with the most important concepts in Hypothesis Testing, we are ready to make our understanding more concrete by looking at a specific Hypothesis Test—namely, the two-sample z-test for means.

As the name implies, this test assumes a normal distribution (z-distribution) and is used to compare the means between two independent groups. This is particularly fitting for our item recommendation module example, where we compare the mean GMV/visitor between the Test and Control groups. The underlying population in this example is assumed to be normally distributed, but even if it weren’t, the Central Limit Theorem (CLT) applies due to the large sample sizes, making the sampling distribution of the means approximately normal.

In general, the two-sample z-test for means is probably the most widely used Hypothesis Test in an online A/B testing context.

#### How does the two-sample z-test for means work?

This test works by measuring how far the observed difference between sample means is from the expected difference under the Null Hypothesis (typically zero), in terms of standard deviations—or more accurately, standard errors. This measurement is called the z-statistic, and the area under the standard normal distribution curve beyond the absolute value of the z-statistic gives us the p-value, which indicates how extreme the observation is.

In essence, the z-test involves just calculating the z-statistic and the corresponding p-value.

#### Equations for Calculating the z-statistic

**Distance:**
The z-statistic measures the distance between the observed difference in sample means and the expected difference under the Null Hypothesis, which is typically zero. This can be expressed as:

$$
(\bar{X}_{\text{test}} - \bar{X}_{\text{control}})
$$

**Standard Error:**
The z-statistic expresses this distance in terms of the standard deviation of the distribution under the Null Hypothesis. The standard deviation of the means is called the standard error, and in the case of the Null Hypothesis, which involves the difference between two means, it is calculated as follows:

By definition:

$$
\text{Standard Error} = \sqrt{\text{Var}(\bar{X}_{\text{test}} - \bar{X}_{\text{control}})}
$$

Because the two samples are independent, the variance of the difference is the sum of the variances of each sample mean:

$$
\text{Standard Error} = \sqrt{\text{Var}(\bar{X}_{\text{test}}) + \text{Var}(\bar{X}_{\text{control}})}
$$

Substituting the variances of the sample means, we get:

$$
\text{Standard Error} = \sqrt{\frac{s^2_{\text{test}}}{n_{\text{test}}} + \frac{s^2_{\text{control}}}{n_{\text{control}}}}
$$

**Note:** The \\(s\\) in the above equation represents the sample standard deviation, which approximates the population standard deviation \\(\sigma\\). The accuracy of this approximation improves with larger sample sizes.

$$
s = \sqrt{\frac{1}{n-1} \sum_{i=1}^{n} (X_i - \bar{X})^2}
$$

Where:
- \\(n\\) is the sample size,
- \\(X_i\\) represents each individual observation,
- \\(\bar{X}\\) is the sample mean.

As mentioned, the Null Hypothesis assumes that there is no difference between the Test and Control distributions. This means we can assume that the standard deviations of both groups are the same. This allows us to simplify the standard error formula by using the pooled standard deviation, \\(s_p\\):

$$
s_p = \sqrt{\frac{(n_{\text{test}} - 1)s_{\text{test}}^2 + (n_{\text{control}} - 1)s_{\text{control}}^2}{n_{\text{test}} + n_{\text{control}} - 2}}
$$

The standard error then simplifies to:

$$
\text{Standard Error} = s_p \sqrt{\frac{1}{n_{\text{test}}} + \frac{1}{n_{\text{control}}}}
$$

Using the above, we then get the z-statistic formula:

$$
Z = \frac{\bar{X}_{\text{test}} - \bar{X}_{\text{control}}}{s_p \sqrt{\frac{1}{n_{\text{test}}} + \frac{1}{n_{\text{control}}}}}
$$

#### Finding the p-value:

Once we have the z-statistic, we can find the corresponding p-value by looking it up in a Z-table or using software, considering the appropriate area under the curve depending on whether the test is left-tailed, right-tailed, or two-tailed.

The above explanation fully captures what a z-test for means entails. However, there is one other important calculation related to the z-test that is typically performed before running the test: the calculation of Statistical Power.

As mentioned earlier:

$$
\text{Statistical Power} = 1 - \beta
$$

Beta \\( \beta \\) represents the probability that the test will fail to reject the Null Hypothesis when the Alternative Hypothesis is true. This occurs when the test statistic under the Alternative Hypothesis falls within the non-significant region of the distribution under the Null Hypothesis, below the critical value \\(\ z_{\alpha} \ \\).

To calculate beta, \\( z_{\alpha} \\) needs to be expressed with respect to the distribution under the Alternative Hypothesis. This transformation is necessary because the critical value \\( z_{\alpha} \\) was originally defined under the Null Hypothesis. To accurately assess the overlap between the Null and Alternative Hypothesis distributions, we must adjust \\( z_{\alpha} \\) to account for the shift in the mean when moving from the Null to the Alternative Hypothesis.

This is done by first expressing the MDE (Minimum Detectable Effect) as a z-statistic ( \\( z_{\text{MDE}} \\) ) and then subtracting \\( z_{\text{MDE}} \\) from \\( z_{\alpha} \\).

$$
z_{\text{MDE}} = \frac{\text{MDE}}{\text{Standard Error}} = \frac{\text{MDE}}{\sqrt{\frac{s^2_{\text{test}}}{n_{\text{test}}} + \frac{s^2_{\text{control}}}{n_{\text{control}}}}}
$$

Beta is therefore calculated as:

$$
\beta = P\left(z > z_{\alpha} - z_{\text{MDE}}\right)
$$

And Statistical Power is:

$$
\text{Statistical Power} = 1 - \beta = 1 - P\left(z > z_{\alpha} - \frac{\text{MDE}}{\sqrt{\frac{s^2_{\text{test}}}{n_{\text{test}}} + \frac{s^2_{\text{control}}}{n_{\text{control}}}}}\right)
$$

Given that Statistical Power is conventionally fixed at 80% and alpha is set to 0.05, we can examine the relationship between MDE and the number of samples for a given sample standard deviation \\( s \\) in the accompanying chart.

### Two Sample z-test for Proportions

This is essentially the same as the two-sample z-test for means, in the sense that it deals with independent groups, requires the sampling distribution to be normal, and determines how extreme the observed data is with respect to the distribution under the Null Hypothesis, by calculating the z-statistic and p-value.

The only difference is that this test deals with proportions in categorical data—specifically binary outcomes (e.g., success/failure)—while the other uses continuous data for calculating means. Whereas the z-test for means is used for testing differences in GMV/visitors, the proportions test is used for testing differences in conversion rates.

#### A Quick Note on Proportions, Ratios, and Means:

Proportions, ratios, and means are often conflated with each other. These are related but different concepts. Proportions represent part of a whole—they are a fraction or percent. Ratios are a comparison or relationship between data—the data can be unrelated and do not have to form part of a whole. Notably, a proportion can be expressed as a ratio, but a ratio is not a proportion. Means are a summary of the distribution of data, i.e., a summary of a series of values to understand what is the “typical” value. This is in contrast to proportions or ratios that involve the division of one quantity by another.

We could take the ratio of means (e.g., mean height of women/mean height of men) or the mean of ratios (e.g., mean of height/weight for women); however, these serve different analytical purposes. The ratio of means shows a relationship between two groups, while the mean of ratios provides a summary within a group—each offering distinct insights depending on the context.

#### Application of the Central Limit Theorem (CLT) to Proportions:

The CLT guarantees that the sampling distribution of means approximates a normal distribution, which allows us to use the z-test. While medians and percentiles do not follow the CLT, the theorem does apply to proportions. This is because proportions can be modeled as the mean of a series of binary outcomes from a binomial distribution. Under the CLT, the sampling distribution of these means (proportions) from a binomial distribution approximates a normal distribution as the sample size increases, enabling us to apply the z-test.

#### Standard Error for the Difference in Proportions:

By definition:

$$

\text{Standard Error} = \sqrt{\text{Var}(\bar{X}_{\text{test}} - \bar{X}_{\text{control}})}

$$

Since the two samples are independent, the variance of the difference is the sum of the variances of each sample mean:

$$

\text{Standard Error} = \sqrt{\text{Var}(\bar{X}_{\text{test}}) + \text{Var}(\bar{X}_{\text{control}})}

$$

Substituting the variances of the sample proportions, we use \\( p_{\text{test}} \\) and \\( p_{\text{control}} \\) to represent the sample proportions for the test and control groups, respectively:

$$

\text{Standard Error} = \sqrt{\frac{p_{\text{test}}(1 - p_{\text{test}})}{n_{\text{test}}} + \frac{p_{\text{control}}(1 - p_{\text{control}})}{n_{\text{control}}}}

$$

Where:
- \\( p_{\text{test}} = \frac{x_{\text{test}}}{n_{\text{test}}} \\) is the proportion of successes in the test group, where \\( x_{\text{test}} \\) is the number of successes in the test group, and \\( n_{\text{test}} \\) is the size of the test group.
- \\( p_{\text{control}} = \frac{x_{\text{control}}}{n_{\text{control}}} \\) is the proportion of successes in the control group, where \\( x_{\text{control}} \\) is the number of successes in the control group, and \\( n_{\text{control}} \\) is the size of the control group.

#### Pooled Estimate:

Under the Null Hypothesis, we assume that the true proportions in both groups are equal, so we use a pooled estimate \\( \hat{p} \\), calculated as:

$$

\hat{p} = \frac{x_{\text{test}} + x_{\text{control}}}{n_{\text{test}} + n_{\text{control}}}

$$

Using \\( \hat{p} \\), the standard error formula becomes:

$$

\text{Standard Error} = \sqrt{\frac{\hat{p}(1 - \hat{p})}{n_{\text{test}}} + \frac{\hat{p}(1 - \hat{p})}{n_{\text{control}}}}

$$

We can then factor out \\( \hat{p}(1 - \hat{p}) \\):

$$

\text{Standard Error} = \sqrt{\hat{p}(1 - \hat{p}) \left( \frac{1}{n_{\text{test}}} + \frac{1}{n_{\text{control}}} \right)}

$$

#### Z-statistic for the Difference in Proportions:

As before, the z-statistic is calculated by dividing the observed difference by the standard error, to measure how many standard errors the observed difference is from the expected difference under the Null Hypothesis:

$$

Z = \frac{p_{\text{test}} - p_{\text{control}}}{\sqrt{\hat{p}(1 - \hat{p}) \left( \frac{1}{n_{\text{test}}} + \frac{1}{n_{\text{control}}} \right)}}

$$

#### Statistical Power:

The formula for Statistical Power in the case of the difference in proportions is fundamentally similar to that in the case of the difference in means:

$$

\text{Statistical Power} = 1 - \beta = 1 - P\left(z > z_{\alpha} - z_{\text{MDE}}\right)

$$

However, due to the difference in how the standard error is calculated for proportions, the formula becomes:

$$

\text{Statistical Power} = 1 - P\left(z > z_{\alpha} - \frac{\text{MDE}}{\sqrt{\hat{p}(1 - \hat{p}) \left( \frac{1}{n_{\text{test}}} + \frac{1}{n_{\text{control}}} \right)}}\right)

$$

Where:
- \\( \hat{p} \\) represents the pooled proportion, calculated as:

$$

\hat{p} = \frac{\text{number of successes in both groups}}{\text{total sample size of both groups}}

$$

- \\( \text{MDE} \\) is the Minimum Detectable Effect, expressed as the difference in proportions you want to detect.

### Other Hypothesis Tests

So far, we have covered two variants of the Z-test: the two-sample Z-test for means and the two-sample Z-test for proportions. However, there are other variations of the Z-test, such as the one-sample Z-test (where instead of a Test and Control group, a single group is compared to some specified threshold) and the paired Z-test (where instead of independent Test and Control groups, the group being measured is related in some way). Beyond the Z-test, there are also various other types of hypothesis tests—some that don't rely on assumptions about the sampling distribution, and others that allow us to assess changes across multiple variables.

Next, we will explore a hypothesis test that measures differences in medians. This test is valuable because medians, being more robust to outliers than means, are an important statistic. Additionally, the test provides a contrast to the Z-test.

### Mann-Whitney U Test

This test tells us if there is a statistically significant difference between the distributions of two samples (i.e., between the Test and Control groups). From that, we can infer whether the difference in medians of the two samples is statistically significant.

Unlike the Z-test, this test does not require the sampling distribution to be normal, or make any assumptions on the sampling or population distributions. In fact, this particular test does not even work directly with the data. Instead, it works by comparing the relative rank of the data across the groups.

Under the Null Hypothesis, the expectation is that there is no difference between the two groups—implying that the ranks are randomly distributed between the groups. Deviations from this expectation are also assessed based on the ranked data. For large samples, these deviations can be further transformed into Z-scores for comparison to a normal distribution. The specifics of this will be illustrated below using an example.

The Mann-Whitney test is applicable to continuous or ordinal data. Due to its applicability to continuous data, we can again leverage our item recommendation module example.

Let us imagine we have 6 visitors in the Control group exposed to the old module and 6 visitors in the Test group exposed to the new module. The GMV/visitor for each visitor in each group is illustrated below.

As mentioned, the test involves pooling the observations from the two samples into one combined sample, keeping track of which sample each observation comes from, and then ranking them from lowest to highest (1 to \\( n_{\text{control}} + n_{\text{test}} \\)).

We then compare the sum of each sample’s across-group rank to its within-group rank. A data point's across-group rank is higher than its within-group rank when a lower-valued data point exists in the other group, pushing the given data point to a higher rank. The difference between the sum of across-group and within-group ranks reflects how much one group's values tend to be larger than the other’s.

For example, the GMV/Visitor data point of 11.3 in the Control group has an across-group rank of 4 but a within-group rank of 3 because there is one Test group data point (11.0) that is lower. Similarly, the data point of 11.5 in the Control group has an across-group rank of 6 but a within-group rank of 4 because there are two Test group data points (11.0 and 11.4) smaller than the Control data point.

In this way, there are 11 instances where the Test group’s data point is smaller than the Control group’s, reflected in the U Statistic of 11 for the Control group.

The U Statistic for the Test group is 25, implying 25 instances where a Control group data point is smaller than a Test group data point.

### U Statistic Formula

To summarize, the formula for the U Statistic using the Control group is:

$$
U_{\text{control}} = R_{\text{control}} - \frac{n_{\text{control}} (n_{\text{control}} + 1)}{2}
$$

Where \\( R_{\text{control}} \\) is the sum of across-group ranks of the Control data, and \\( \frac{n_{\text{control}} (n_{\text{control}} + 1)}{2} \\) is the sum of within-group ranks of the Control data.

The U statistic is a rank-based measure of separation between two distributions. Under the Null Hypothesis, we assume there is no difference between the Test and Control distributions, meaning half of the values in one group will rank higher than those in the other group.

### Statistical Significance

To determine statistical significance, we use the smaller of the two U statistics and compare it to the expected distribution under the Null Hypothesis. For small samples, we compare the U statistic to a critical value from the Mann-Whitney distribution table to get an exact p-value.

For larger samples, we use the Central Limit Theorem (CLT), which guarantees that the U statistic approximates a normal distribution.

The Z-score of the U statistic is calculated as:

$$
Z = \frac{U - \mu_U}{\sigma_U}
$$

Where:

- \\( \mu_U \\) is the mean, calculated as \\( \mu_U = \frac{n_1 \times n_2}{2} \\).
- \\( \sigma_U \\) is the standard deviation, calculated as:

$$
\sigma_U = \sqrt{\frac{n_1 \times n_2 \times (n_1 + n_2 + 1)}{12}}
$$

If there are ties in the rankings, the formula for \\( \sigma_U \\) changes.

For our example, we get \\( \mu_U = 18 \\) and \\( \sigma_U = 6.244 \\). Given \\( U_{\text{control}} = 11 \\) and \\( U_{\text{test}} = 25 \\), we calculate:

$$
Z_{\text{control}} = \frac{11 - 18}{6.244} \approx -1.12
$$

$$
Z_{\text{test}} = \frac{25 - 18}{6.244} \approx 1.12
$$

Both U statistics yield symmetric Z-scores and the same p-value (0.2623), which is not statistically significant.

### A Disclaimer on Inferring Medians

The Mann-Whitney U test can detect differences between distributions, but it does not necessarily imply that the medians are different unless the two distributions have the same shape. Differences in the shape of the distributions (e.g., spread or skewness) can lead to rejection of the Null Hypothesis even when the medians are the same.

This is why Mann-Whitney tests are often reported as detecting significant differences between groups, but not necessarily differences in medians unless it is assumed that the distributions are similarly shaped.

### Statistical Power

The statistical power calculation for the Mann-Whitney test is more complex than that for Z-tests. For small samples, Monte Carlo simulations or exact methods are used. For large samples, the asymptotic normal approximation can be applied, similar to the Z-test.

The effect size in the Mann-Whitney test is often expressed as the probability of superiority:

$$
\text{Probability of Superiority} = \frac{U}{n_1 \times n_2}
$$

This gives the likelihood that a randomly selected value from the Test group will exceed one from the Control group.

In our example, if we want a probability of superiority of 0.65, we calculate the U statistic for the MDE as:

$$
U_{\text{MDE}} = n_{\text{control}} \times n_{\text{test}} \times 0.65 = 6 \times 6 \times 0.65 = 23.4
$$

The Z-score for the MDE is then:

$$
Z_{\text{MDE}} = \frac{U_{\text{MDE}} - \mu_U}{\sigma_U} = 0.865
$$

For a 5% significance level, the critical value of \\( Z_{\alpha} \\) is 1.96, so the statistical power is:

$$
\text{Power} = P(Z > Z_{\text{MDE}} - Z_{\alpha}) \approx 86.2\%
$$
