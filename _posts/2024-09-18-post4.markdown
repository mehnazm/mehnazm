---
layout: post
title: "The Fundamentals of Hypothesis Testing Concepts "
date: 2024-09-18
categories: main 
image: /assets/images/post4/img1.jpg 
excerpt: "??"      

---

### Two Sample z-test for Means

Now that we have familiarized ourselves with the most important concepts in Hypothesis Testing, we are ready to make our understanding more concrete by looking at a specific Hypothesis Test—namely, the two-sample z-test for means.

As the name implies, this test assumes a normal distribution (z-distribution) and is used to compare the means between two independent groups. This is particularly fitting for our item recommendation module example, where we compare the mean GMV/visitor between the Test and Control groups. The underlying population in this example is assumed to be normally distributed, but even if it weren’t, the Central Limit Theorem (CLT) applies due to the large sample sizes, making the sampling distribution of the means approximately normal.

In general, the two-sample z-test for means is probably the most widely used Hypothesis Test in an online A/B testing context.

#### How does the two-sample z-test for means work?

This test works by measuring how far the observed difference between sample means is from the expected difference under the Null Hypothesis (typically zero), in terms of standard deviations—or more accurately, standard errors. This measurement is called the z-statistic, and the area under the standard normal distribution curve beyond the absolute value of the z-statistic gives us the p-value, which indicates how extreme the observation is.

In essence, the z-test involves just calculating the z-statistic and the corresponding p-value.

#### Equations for Calculating the z-statistic

**Distance:**
The z-statistic measures the distance between the observed difference in sample means and the expected difference under the Null Hypothesis, which is typically zero. This can be expressed as:

$$
(\bar{X}_{\text{test}} - \bar{X}_{\text{control}})
$$

**Standard Error:**
The z-statistic expresses this distance in terms of the standard deviation of the distribution under the Null Hypothesis. The standard deviation of the means is called the standard error, and in the case of the Null Hypothesis, which involves the difference between two means, it is calculated as follows:

By definition:

$$
\text{Standard Error} = \sqrt{\text{Var}(\bar{X}_{\text{test}} - \bar{X}_{\text{control}})}
$$

Because the two samples are independent, the variance of the difference is the sum of the variances of each sample mean:

$$
\text{Standard Error} = \sqrt{\text{Var}(\bar{X}_{\text{test}}) + \text{Var}(\bar{X}_{\text{control}})}
$$

Substituting the variances of the sample means, we get:

$$
\text{Standard Error} = \sqrt{\frac{s^2_{\text{test}}}{n_{\text{test}}} + \frac{s^2_{\text{control}}}{n_{\text{control}}}}
$$

**Note:** The \\(s\\) in the above equation represents the sample standard deviation, which approximates the population standard deviation \\(\sigma\\). The accuracy of this approximation improves with larger sample sizes.

$$
s = \sqrt{\frac{1}{n-1} \sum_{i=1}^{n} (X_i - \bar{X})^2}
$$

Where:
- \\(n\\) is the sample size,
- \\(X_i\\) represents each individual observation,
- \\(\bar{X}\\) is the sample mean.

As mentioned, the Null Hypothesis assumes that there is no difference between the Test and Control distributions. This means we can assume that the standard deviations of both groups are the same. This allows us to simplify the standard error formula by using the pooled standard deviation, \\(s_p\\):

$$
s_p = \sqrt{\frac{(n_{\text{test}} - 1)s_{\text{test}}^2 + (n_{\text{control}} - 1)s_{\text{control}}^2}{n_{\text{test}} + n_{\text{control}} - 2}}
$$

The standard error then simplifies to:

$$
\text{Standard Error} = s_p \sqrt{\frac{1}{n_{\text{test}}} + \frac{1}{n_{\text{control}}}}
$$

Using the above, we then get the z-statistic formula:

$$
Z = \frac{\bar{X}_{\text{test}} - \bar{X}_{\text{control}}}{s_p \sqrt{\frac{1}{n_{\text{test}}} + \frac{1}{n_{\text{control}}}}}
$$

#### Finding the p-value:

Once we have the z-statistic, we can find the corresponding p-value by looking it up in a Z-table or using software, considering the appropriate area under the curve depending on whether the test is left-tailed, right-tailed, or two-tailed.

The above explanation fully captures what a z-test for means entails. However, there is one other important calculation related to the z-test that is typically performed before running the test: the calculation of Statistical Power.

As mentioned earlier:

$$
\text{Statistical Power} = 1 - \beta
$$

Beta \\( \beta \\) represents the probability that the test will fail to reject the Null Hypothesis when the Alternative Hypothesis is true. This occurs when the test statistic under the Alternative Hypothesis falls within the non-significant region of the distribution under the Null Hypothesis, below the critical value \\(\ z_{\alpha} \ \\).

To calculate beta, \\( z_{\alpha} \\) needs to be expressed with respect to the distribution under the Alternative Hypothesis. This transformation is necessary because the critical value \\( z_{\alpha} \\) was originally defined under the Null Hypothesis. To accurately assess the overlap between the Null and Alternative Hypothesis distributions, we must adjust \\( z_{\alpha} \\) to account for the shift in the mean when moving from the Null to the Alternative Hypothesis.

This is done by first expressing the MDE (Minimum Detectable Effect) as a z-statistic ( \\( z_{\text{MDE}} \\) ) and then subtracting \\( z_{\text{MDE}} \\) from \\( z_{\alpha} \\).

$$
z_{\text{MDE}} = \frac{\text{MDE}}{\text{Standard Error}} = \frac{\text{MDE}}{\sqrt{\frac{s^2_{\text{test}}}{n_{\text{test}}} + \frac{s^2_{\text{control}}}{n_{\text{control}}}}}
$$

Beta is therefore calculated as:

$$
\beta = P\left(z > z_{\alpha} - z_{\text{MDE}}\right)
$$

And Statistical Power is:

$$
\text{Statistical Power} = 1 - \beta = 1 - P\left(z > z_{\alpha} - \frac{\text{MDE}}{\sqrt{\frac{s^2_{\text{test}}}{n_{\text{test}}} + \frac{s^2_{\text{control}}}{n_{\text{control}}}}}\right)
$$

Given that Statistical Power is conventionally fixed at 80% and alpha is set to 0.05, we can examine the relationship between MDE and the number of samples for a given sample standard deviation \\( s \\) in the accompanying chart.

### Two Sample z-test for Proportions

This is essentially the same as the two-sample z-test for means, in the sense that it deals with independent groups, requires the sampling distribution to be normal, and determines how extreme the observed data is with respect to the distribution under the Null Hypothesis, by calculating the z-statistic and p-value.

The only difference is that this test deals with proportions in categorical data—specifically binary outcomes (e.g., success/failure)—while the other uses continuous data for calculating means. Whereas the z-test for means is used for testing differences in GMV/visitors, the proportions test is used for testing differences in conversion rates.

#### A Quick Note on Proportions, Ratios, and Means:

Proportions, ratios, and means are often conflated with each other. These are related but different concepts. Proportions represent part of a whole—they are a fraction or percent. Ratios are a comparison or relationship between data—the data can be unrelated and do not have to form part of a whole. Notably, a proportion can be expressed as a ratio, but a ratio is not a proportion. Means are a summary of the distribution of data, i.e., a summary of a series of values to understand what is the “typical” value. This is in contrast to proportions or ratios that involve the division of one quantity by another.

We could take the ratio of means (e.g., mean height of women/mean height of men) or the mean of ratios (e.g., mean of height/weight for women); however, these serve different analytical purposes. The ratio of means shows a relationship between two groups, while the mean of ratios provides a summary within a group—each offering distinct insights depending on the context.

#### Application of the Central Limit Theorem (CLT) to Proportions:

The CLT guarantees that the sampling distribution of means approximates a normal distribution, which allows us to use the z-test. While medians and percentiles do not follow the CLT, the theorem does apply to proportions. This is because proportions can be modeled as the mean of a series of binary outcomes from a binomial distribution. Under the CLT, the sampling distribution of these means (proportions) from a binomial distribution approximates a normal distribution as the sample size increases, enabling us to apply the z-test.

#### Standard Error for the Difference in Proportions:

By definition:

$$

\text{Standard Error} = \sqrt{\text{Var}(\bar{X}_{\text{test}} - \bar{X}_{\text{control}})}

$$

Since the two samples are independent, the variance of the difference is the sum of the variances of each sample mean:

$$

\text{Standard Error} = \sqrt{\text{Var}(\bar{X}_{\text{test}}) + \text{Var}(\bar{X}_{\text{control}})}

$$

Substituting the variances of the sample proportions, we use \\( p_{\text{test}} \\) and \\( p_{\text{control}} \\) to represent the sample proportions for the test and control groups, respectively:

$$

\text{Standard Error} = \sqrt{\frac{p_{\text{test}}(1 - p_{\text{test}})}{n_{\text{test}}} + \frac{p_{\text{control}}(1 - p_{\text{control}})}{n_{\text{control}}}}

$$

Where:
- \\( p_{\text{test}} = \frac{x_{\text{test}}}{n_{\text{test}}} \\) is the proportion of successes in the test group, where \\( x_{\text{test}} \\) is the number of successes in the test group, and \\( n_{\text{test}} \\) is the size of the test group.
- \\( p_{\text{control}} = \frac{x_{\text{control}}}{n_{\text{control}}} \\) is the proportion of successes in the control group, where \\( x_{\text{control}} \\) is the number of successes in the control group, and \\( n_{\text{control}} \\) is the size of the control group.

#### Pooled Estimate:

Under the Null Hypothesis, we assume that the true proportions in both groups are equal, so we use a pooled estimate \\( \hat{p} \\), calculated as:

$$

\hat{p} = \frac{x_{\text{test}} + x_{\text{control}}}{n_{\text{test}} + n_{\text{control}}}

$$

Using \\( \hat{p} \\), the standard error formula becomes:

$$

\text{Standard Error} = \sqrt{\frac{\hat{p}(1 - \hat{p})}{n_{\text{test}}} + \frac{\hat{p}(1 - \hat{p})}{n_{\text{control}}}}

$$

We can then factor out \\( \hat{p}(1 - \hat{p}) \\):

$$

\text{Standard Error} = \sqrt{\hat{p}(1 - \hat{p}) \left( \frac{1}{n_{\text{test}}} + \frac{1}{n_{\text{control}}} \right)}

$$

#### Z-statistic for the Difference in Proportions:

As before, the z-statistic is calculated by dividing the observed difference by the standard error, to measure how many standard errors the observed difference is from the expected difference under the Null Hypothesis:

$$

Z = \frac{p_{\text{test}} - p_{\text{control}}}{\sqrt{\hat{p}(1 - \hat{p}) \left( \frac{1}{n_{\text{test}}} + \frac{1}{n_{\text{control}}} \right)}}

$$

#### Statistical Power:

The formula for Statistical Power in the case of the difference in proportions is fundamentally similar to that in the case of the difference in means:

$$

\text{Statistical Power} = 1 - \beta = 1 - P\left(z > z_{\alpha} - z_{\text{MDE}}\right)

$$

However, due to the difference in how the standard error is calculated for proportions, the formula becomes:

$$

\text{Statistical Power} = 1 - P\left(z > z_{\alpha} - \frac{\text{MDE}}{\sqrt{\hat{p}(1 - \hat{p}) \left( \frac{1}{n_{\text{test}}} + \frac{1}{n_{\text{control}}} \right)}}\right)

$$

Where:
- \\( \hat{p} \\) represents the pooled proportion, calculated as:

$$

\hat{p} = \frac{\text{number of successes in both groups}}{\text{total sample size of both groups}}

$$

- \\( \text{MDE} \\) is the Minimum Detectable Effect, expressed as the difference in proportions you want to detect.

